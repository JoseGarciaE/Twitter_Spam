{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4d93e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704d604",
   "metadata": {},
   "source": [
    "# Twitter API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "699f8293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c40c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bearer_token = os.environ['BEARER_TOKEN']\n",
    "\n",
    "def create_url(tweetIDS):\n",
    "    ids = \"ids=\" + tweetIDS\n",
    "    tweet_fields = \"tweet.fields=source,lang,created_at,public_metrics,context_annotations\"\n",
    "    url = \"https://api.twitter.com/2/tweets?{}&{}\".format(ids, tweet_fields)\n",
    "    return url\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5441f",
   "metadata": {},
   "source": [
    "# Importing Research Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d31719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data sourced from: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0182487\n",
    "\n",
    "df = pd.read_excel('pone.0182487.s003.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4536d85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1 Table - Tweet data and labels</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have used the data according to the Twitter...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tweet id</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732113301144883204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    S1 Table - Tweet data and labels Unnamed: 1\n",
       "0  We have used the data according to the Twitter...        NaN\n",
       "1                                                NaN        NaN\n",
       "2                                                NaN        NaN\n",
       "3                                           Tweet id      Label\n",
       "4                                 732113301144883204          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb814117",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732113301144883204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>732113301182746624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>732113301145014272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>732113301149089794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>732113301178552320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id spam\n",
       "4  732113301144883204    0\n",
       "5  732113301182746624    0\n",
       "6  732113301145014272    0\n",
       "7  732113301149089794    0\n",
       "8  732113301178552320    0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fixing columnns and rows\n",
    "df = df.drop([0,1,2,3])\n",
    "df = df.set_axis(['id', 'spam'], axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e27bfa",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c05f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Count: 9945\n",
      "Good Count: 90055\n",
      "Spam to Good Ratio: 0.09945\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spamCount = df[df['spam']==1].shape[0]\n",
    "goodCount = df[df['spam']==0].shape[0]\n",
    "\n",
    "sns.countplot(data=df, x='spam')\n",
    "\n",
    "print('Spam Count:', spamCount)\n",
    "print('Good Count:', goodCount)\n",
    "print('Spam to Good Ratio:', spamCount/(spamCount+goodCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a70c43",
   "metadata": {},
   "source": [
    "# Collecting Tweet data given research data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e633f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetIDS = []\n",
    "# temp = ''\n",
    "# for count, val in enumerate(df['id']):\n",
    "#     temp = temp + val + ','\n",
    "#     if count != 0 and count % 99 == 0:\n",
    "#         temp = temp[:-1]\n",
    "#         tweetIDS.append(temp)\n",
    "#         temp = ''\n",
    "\n",
    "# tweetJSON = []\n",
    "\n",
    "# for i in tweetIDS:\n",
    "#     url = create_url(i)\n",
    "#     json_response = connect_to_endpoint(url)\n",
    "#     tweetJSON.append(json_response)\n",
    "\n",
    "# tweetDF = pd.DataFrame(columns=['id', 'lang', 'created_at', 'source', 'text', 'like_count', 'reply_count', 'quote_count'])\n",
    "\n",
    "# for val in tweetJSON:\n",
    "#     for i in val['data']:\n",
    "#         temp = {\n",
    "#             'id': i['id'],\n",
    "#             'lang': i['lang'],\n",
    "#             'created_at': i['created_at'],\n",
    "#             'source': i['source'],\n",
    "#             'text': i['text'],\n",
    "#             'like_count': i['public_metrics']['like_count'],\n",
    "#             'reply_count': i['public_metrics']['reply_count'],\n",
    "#             'quote_count': i['public_metrics']['quote_count']\n",
    "#         }\n",
    "        \n",
    "#         tweetDF = tweetDF.append(temp, ignore_index=True)\n",
    "\n",
    "# tweetDF.to_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9c542",
   "metadata": {},
   "source": [
    "<!-- tweetIDS = []\n",
    "temp = ''\n",
    "for count, val in enumerate(df['id']):\n",
    "    temp = temp + val + ','\n",
    "    if count != 0 and count % 99 == 0:\n",
    "        temp = temp[:-1]\n",
    "        tweetIDS.append(temp)\n",
    "        temp = ''\n",
    "\n",
    "tweetJSON = []\n",
    "\n",
    "for i in tweetIDS:\n",
    "    url = create_url(i)\n",
    "    json_response = connect_to_endpoint(url)\n",
    "    tweetJSON.append(json_response)\n",
    "\n",
    "tweetDF = pd.DataFrame(columns=['id', 'lang', 'created_at', 'source', 'text', 'like_count', 'reply_count', 'quote_count'])\n",
    "\n",
    "for val in tweetJSON:\n",
    "    for i in val['data']:\n",
    "        temp = {\n",
    "            'id': i['id'],\n",
    "            'lang': i['lang'],\n",
    "            'created_at': i['created_at'],\n",
    "            'source': i['source'],\n",
    "            'text': i['text'],\n",
    "            'like_count': i['public_metrics']['like_count'],\n",
    "            'reply_count': i['public_metrics']['reply_count'],\n",
    "            'quote_count': i['public_metrics']['quote_count']\n",
    "        }\n",
    "        \n",
    "        tweetDF = tweetDF.append(temp, ignore_index=True)\n",
    "\n",
    "tweetDF.to_csv('tweets.csv') -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2065b49",
   "metadata": {},
   "source": [
    "# Combing Tweet Data and Research Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fcb321e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732113301182746624</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:47.000Z</td>\n",
       "      <td>Tweetbot for iΟS</td>\n",
       "      <td>RT @odinodin: I just made a tool for inspectin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732113301145014272</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:47.000Z</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>HAPPY BIRTHDAY JOSEPH 💓 @JosephMorgan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>732113301149089794</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:47.000Z</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>RT @zeecinema: Yeh inka dopahar ka program hai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>732113305376940032</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:48.000Z</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>RT @iitian_kshitij: Actually they have become ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732113305347612672</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:48.000Z</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@JaimesonPaul lock all windows and doors don't...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id lang                created_at               source  \\\n",
       "0  732113301182746624   en  2016-05-16T07:39:47.000Z     Tweetbot for iΟS   \n",
       "1  732113301145014272   en  2016-05-16T07:39:47.000Z  Twitter for Android   \n",
       "2  732113301149089794   en  2016-05-16T07:39:47.000Z     Twitter for iPad   \n",
       "3  732113305376940032   en  2016-05-16T07:39:48.000Z  Twitter for Android   \n",
       "4  732113305347612672   en  2016-05-16T07:39:48.000Z   Twitter for iPhone   \n",
       "\n",
       "                                                text  like_count  reply_count  \\\n",
       "0  RT @odinodin: I just made a tool for inspectin...           0            0   \n",
       "1              HAPPY BIRTHDAY JOSEPH 💓 @JosephMorgan           0            0   \n",
       "2  RT @zeecinema: Yeh inka dopahar ka program hai...           0            0   \n",
       "3  RT @iitian_kshitij: Actually they have become ...           0            0   \n",
       "4  @JaimesonPaul lock all windows and doors don't...           0            1   \n",
       "\n",
       "   quote_count  spam  \n",
       "0            0     0  \n",
       "1            0     0  \n",
       "2            0     0  \n",
       "3            0     0  \n",
       "4            0     0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetDF = pd.read_csv('tweets.csv', index_col=[0])\n",
    "tweetDF['id'] = tweetDF['id'].astype(str)\n",
    "tweetDF['source'] = tweetDF['source'].astype(str)\n",
    "tweetDF['text'] = tweetDF['text'].astype(str)\n",
    "\n",
    "\n",
    "df['id'] = df['id'].astype(str)\n",
    "df['spam'] = df['spam'].astype(int)\n",
    "\n",
    "data = pd.merge(tweetDF,df, how='inner', on='id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b123ea",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a59edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07799da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    doc = nlp(x.lower())\n",
    "    lemmas = [token.lemma_ for token in doc \n",
    "          if token.lemma_.isalnum() and token.lemma_ not in stopwords]\n",
    "    x = ' '.join(lemmas)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "015d0b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732113301182746624</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:47.000Z</td>\n",
       "      <td>Tweetbot for iΟS</td>\n",
       "      <td>rt I tool inspect datum reagent app tree struc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732113301145014272</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:47.000Z</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>happy birthday joseph</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>732113301149089794</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:47.000Z</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>rt yeh inka dopahar ka program hai watch phir ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>732113305376940032</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:48.000Z</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>rt actually middle man</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732113305347612672</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-05-16T07:39:48.000Z</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>lock window door investigate odd noise sure ce...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id lang                created_at               source  \\\n",
       "0  732113301182746624   en  2016-05-16T07:39:47.000Z     Tweetbot for iΟS   \n",
       "1  732113301145014272   en  2016-05-16T07:39:47.000Z  Twitter for Android   \n",
       "2  732113301149089794   en  2016-05-16T07:39:47.000Z     Twitter for iPad   \n",
       "3  732113305376940032   en  2016-05-16T07:39:48.000Z  Twitter for Android   \n",
       "4  732113305347612672   en  2016-05-16T07:39:48.000Z   Twitter for iPhone   \n",
       "\n",
       "                                                text  like_count  reply_count  \\\n",
       "0  rt I tool inspect datum reagent app tree struc...           0            0   \n",
       "1                              happy birthday joseph           0            0   \n",
       "2  rt yeh inka dopahar ka program hai watch phir ...           0            0   \n",
       "3                             rt actually middle man           0            0   \n",
       "4  lock window door investigate odd noise sure ce...           0            1   \n",
       "\n",
       "   quote_count  spam  \n",
       "0            0     0  \n",
       "1            0     0  \n",
       "2            0     0  \n",
       "3            0     0  \n",
       "4            0     0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788740e8",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "563b05a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Count: 3345\n",
      "Good Count: 43390\n",
      "Spam to Good Ratio: 0.07157376698405905\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spamCount = data[data['spam']==1].shape[0]\n",
    "goodCount = data[data['spam']==0].shape[0]\n",
    "\n",
    "sns.countplot(data=data, x='spam')\n",
    "\n",
    "print('Spam Count:', spamCount)\n",
    "print('Good Count:', goodCount)\n",
    "print('Spam to Good Ratio:', spamCount/(spamCount+goodCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6f870ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c594c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd0824",
   "metadata": {},
   "source": [
    "# Predicting SPAM through Tweet Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c2491",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ee74099",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['spam'], test_size=1/3)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_X_train = vectorizer.fit_transform(X_train)\n",
    "tfidf_X_test  = vectorizer.transform(X_test)\n",
    "\n",
    "vectorizer_ng1 = CountVectorizer(ngram_range=(1,1))\n",
    "ng1_X_train = vectorizer_ng1.fit_transform(X_train)\n",
    "ng1_X_test  = vectorizer_ng1.transform(X_test)\n",
    "\n",
    "vectorizer_ng2 = CountVectorizer(ngram_range=(1,2))\n",
    "ng2_X_train = vectorizer_ng2.fit_transform(X_train)\n",
    "ng2_X_test  = vectorizer_ng2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c0e6775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using Logistic Regression\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     14507\n",
      "           1       0.96      0.54      0.69      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.96      0.77      0.84     15579\n",
      "weighted avg       0.97      0.97      0.96     15579\n",
      "\n",
      "[[14482    25]\n",
      " [  491   581]]\n",
      "0.9668784902753707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     14507\n",
      "           1       0.93      0.63      0.75      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.95      0.81      0.87     15579\n",
      "weighted avg       0.97      0.97      0.97     15579\n",
      "\n",
      "[[14457    50]\n",
      " [  400   672]]\n",
      "0.9711149624494512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     14507\n",
      "           1       0.96      0.66      0.78      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.97      0.83      0.88     15579\n",
      "weighted avg       0.97      0.97      0.97     15579\n",
      "\n",
      "[[14479    28]\n",
      " [  369   703]]\n",
      "0.9745169779831825\n",
      "--------------------------------------------------\n",
      "\n",
      "Predicting using Random Forest\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     14507\n",
      "           1       0.96      0.66      0.78      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.97      0.83      0.89     15579\n",
      "weighted avg       0.97      0.97      0.97     15579\n",
      "\n",
      "[[14477    30]\n",
      " [  361   711]]\n",
      "0.9749021118171898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     14507\n",
      "           1       0.90      0.68      0.78      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.94      0.84      0.88     15579\n",
      "weighted avg       0.97      0.97      0.97     15579\n",
      "\n",
      "[[14430    77]\n",
      " [  341   731]]\n",
      "0.9731690095641569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     14507\n",
      "           1       0.93      0.67      0.77      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.95      0.83      0.88     15579\n",
      "weighted avg       0.97      0.97      0.97     15579\n",
      "\n",
      "[[14450    57]\n",
      " [  359   713]]\n",
      "0.973297387508826\n",
      "--------------------------------------------------\n",
      "\n",
      "Predicting using Naive Bayes\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     14507\n",
      "           1       1.00      0.47      0.64      1072\n",
      "\n",
      "    accuracy                           0.96     15579\n",
      "   macro avg       0.98      0.74      0.81     15579\n",
      "weighted avg       0.96      0.96      0.96     15579\n",
      "\n",
      "[[14505     2]\n",
      " [  567   505]]\n",
      "0.9634764747416393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     14507\n",
      "           1       0.93      0.59      0.72      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.95      0.79      0.85     15579\n",
      "weighted avg       0.97      0.97      0.97     15579\n",
      "\n",
      "[[14462    45]\n",
      " [  439   633]]\n",
      "0.9689325373900763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     14507\n",
      "           1       0.96      0.63      0.76      1072\n",
      "\n",
      "    accuracy                           0.97     15579\n",
      "   macro avg       0.97      0.81      0.87     15579\n",
      "weighted avg       0.97      0.97      0.97     15579\n",
      "\n",
      "[[14481    26]\n",
      " [  399   673]]\n",
      "0.9727196867578151\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['Logistic Regression', \n",
    "         'Random Forest', \n",
    "         'Naive Bayes']\n",
    "\n",
    "models = [LogisticRegression(), \n",
    "          RandomForestClassifier(), \n",
    "          MultinomialNB()]\n",
    "\n",
    "for cnt, model in enumerate(models):\n",
    "    \n",
    "    print('Predicting using {}'.format(names[cnt]))\n",
    "    print('**************************************************')\n",
    "    \n",
    "    model.fit(tfidf_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(tfidf_X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    model.fit(ng1_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(ng1_X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    model.fit(ng2_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(ng2_X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    print('--------------------------------------------------\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3362c81",
   "metadata": {},
   "source": [
    "# Predicting SPAM through Tweet Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3b93d",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48f78cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['source'], data['spam'], test_size=1/3)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_X_train = vectorizer.fit_transform(X_train)\n",
    "tfidf_X_test  = vectorizer.transform(X_test)\n",
    "\n",
    "vectorizer_ng1 = CountVectorizer(ngram_range=(1,1))\n",
    "count_X_train = vectorizer_ng1.fit_transform(X_train)\n",
    "count_X_test  = vectorizer_ng1.transform(X_test)\n",
    "\n",
    "vectorizer_ng2 = CountVectorizer(ngram_range=(1,2))\n",
    "count_X_train = vectorizer_ng2.fit_transform(X_train)\n",
    "count_X_test  = vectorizer_ng2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736dfe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using Logistic Regression\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     14430\n",
      "           1       0.97      0.41      0.58      1149\n",
      "\n",
      "    accuracy                           0.96     15579\n",
      "   macro avg       0.96      0.71      0.78     15579\n",
      "weighted avg       0.96      0.96      0.95     15579\n",
      "\n",
      "[[14417    13]\n",
      " [  673   476]]\n",
      "0.9559663649784967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     14430\n",
      "           1       0.08      0.00      0.01      1149\n",
      "\n",
      "    accuracy                           0.92     15579\n",
      "   macro avg       0.50      0.50      0.48     15579\n",
      "weighted avg       0.86      0.92      0.89     15579\n",
      "\n",
      "[[14386    44]\n",
      " [ 1145     4]]\n",
      "0.9236793118942166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     14430\n",
      "           1       0.07      0.01      0.02      1149\n",
      "\n",
      "    accuracy                           0.92     15579\n",
      "   macro avg       0.50      0.50      0.49     15579\n",
      "weighted avg       0.86      0.92      0.89     15579\n",
      "\n",
      "[[14305   125]\n",
      " [ 1139    10]]\n",
      "0.9188651389691251\n",
      "--------------------------------------------------\n",
      "\n",
      "Predicting using Random Forest\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     14430\n",
      "           1       0.95      0.44      0.60      1149\n",
      "\n",
      "    accuracy                           0.96     15579\n",
      "   macro avg       0.95      0.72      0.79     15579\n",
      "weighted avg       0.96      0.96      0.95     15579\n",
      "\n",
      "[[14401    29]\n",
      " [  640   509]]\n",
      "0.9570575775081841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     14430\n",
      "           1       0.09      0.03      0.05      1149\n",
      "\n",
      "    accuracy                           0.91     15579\n",
      "   macro avg       0.51      0.50      0.50     15579\n",
      "weighted avg       0.87      0.91      0.88     15579\n",
      "\n",
      "[[14068   362]\n",
      " [ 1113    36]]\n",
      "0.9053212658065345\n"
     ]
    }
   ],
   "source": [
    "names = ['Logistic Regression', \n",
    "         'Random Forest', \n",
    "         'Naive Bayes']\n",
    "\n",
    "models = [LogisticRegression(), \n",
    "          RandomForestClassifier(), \n",
    "          MultinomialNB()]\n",
    "\n",
    "for cnt, model in enumerate(models):\n",
    "    \n",
    "    print('Predicting using {}'.format(names[cnt]))\n",
    "    print('**************************************************')\n",
    "    \n",
    "    model.fit(tfidf_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(tfidf_X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    model.fit(ng1_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(ng1_X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    model.fit(ng2_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(ng2_X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    print('--------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97255b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d1153b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
